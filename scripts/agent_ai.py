import sys
import json
import sqlite3
import whisper
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
import logging
import threading
import time
import subprocess
import google.generativeai as genai
from pydub import AudioSegment
from pydub.effects import normalize
import noisereduce as nr
import librosa
from langdetect import detect
import re
import gtts
from gtts import gTTS
import pygame
import edge_tts
import asyncio
import tempfile
import os
import pickle
from typing import List, Tuple, Optional

load_dotenv()

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

class VoiceAssistant:
    def __init__(self, fallback_only=False):
        """
        Initialisation avec SQLite et support pour all_docs.json
        """
        try:
            self.fallback_only = fallback_only
            self.db_available = False
            self.db_path = "assistant_database.db"
            self.knowledge_base_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "database", "all_docs.json")

            
            self.setup_models()
            if not fallback_only:
                try:
                    self.setup_sqlite_database()
                    self.load_knowledge_base()
                    self.db_available = True
                    logger.info("âœ… Base de donnÃ©es SQLite initialisÃ©e")
                except Exception as e:
                    logger.warning(f"âš ï¸ Base de donnÃ©es non disponible, mode fallback activÃ©: {e}")
                    self.db_available = False
            else:
                logger.info("ğŸ”„ Mode fallback uniquement activÃ©")
            
            self.setup_language_patterns()
            self.setup_tts()
            
            logger.info("âœ… Assistant vocal initialisÃ© avec succÃ¨s")
            
        except Exception as e:
            logger.error(f"âš ï¸ Erreur lors de l'initialisation: {e}")
            raise

    def setup_models(self):
        """Initialisation des modÃ¨les IA"""
        try:
            logger.info("Chargement du modÃ¨le Whisper...")
            self.whisper_model = whisper.load_model("medium")
            
            logger.info("Chargement du modÃ¨le d'embedding...")
            self.model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
            
            logger.info("Configuration du modÃ¨le Gemini...")
            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            
            logger.info("ModÃ¨les chargÃ©s avec succÃ¨s")
        except Exception as e:
            logger.error(f"Erreur lors du chargement des modÃ¨les: {e}")
            raise

    def setup_sqlite_database(self):
        """Configuration de la base de donnÃ©es SQLite"""
        try:
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.conn.execute('PRAGMA foreign_keys = ON')
            
            self.create_tables()
            
            logger.info("Base de donnÃ©es SQLite configurÃ©e avec succÃ¨s")
            
        except Exception as e:
            logger.error(f"Erreur lors de la configuration SQLite: {e}")
            raise

    def create_tables(self):
        """CrÃ©er les tables nÃ©cessaires"""
        cursor = self.conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                brand TEXT,
                category TEXT,
                price REAL,
                description TEXT,
                usage_instructions TEXT,
                ingredients TEXT,
                size TEXT,
                stock_quantity INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS product_embeddings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_id INTEGER,
                text_content TEXT,
                embedding BLOB,
                FOREIGN KEY (product_id) REFERENCES products (id)
            )
        ''')
        
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_product_name ON products(name)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_product_category ON products(category)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_embedding_product_id ON product_embeddings(product_id)')
        
        self.conn.commit()
        logger.info("Tables crÃ©Ã©es avec succÃ¨s")

    def load_knowledge_base(self):
        """Charger all_docs.json dans SQLite si la base est vide"""
        try:
            cursor = self.conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM products")
            count = cursor.fetchone()[0]

            if count > 0:
                logger.info(f" La base SQLite contient dÃ©jÃ  {count} produits. Chargement ignorÃ©.")
                return

            if not os.path.exists(self.knowledge_base_path):
                logger.warning(f"âš ï¸ Fichier {self.knowledge_base_path} non trouvÃ©.")
                return

            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                docs_data = json.load(f)

            logger.info(f" Chargement de {len(docs_data)} produits depuis {self.knowledge_base_path}...")

            for i, doc in enumerate(docs_data):
                try:
                    product_data = self.parse_document(doc)
                    if product_data:
                        product_id = self.insert_product(product_data)

                        text_content = self.create_searchable_text(product_data)
                        embedding = self.model.encode([text_content])[0]
                        self.insert_embedding(product_id, text_content, embedding)

                        if (i + 1) % 10 == 0:
                            logger.info(f"âœ”ï¸ {i + 1}/{len(docs_data)} produits traitÃ©s")

                except Exception as e:
                    logger.error(f"âš ï¸ Erreur document {i} : {e}")
                    continue

            self.conn.commit()
            logger.info("âœ… Base de connaissances importÃ©e avec succÃ¨s dans SQLite.")

        except Exception as e:
            logger.error(f"ğŸš¨ Erreur load_knowledge_base : {e}")
            raise

    def parse_document(self, doc):
        """Parser un document JSON selon la structure Paralabel"""
        try:
            if isinstance(doc, dict):
                title = doc.get('title', 'Produit inconnu')
                brand = self.extract_brand_from_title(title)
                
                category = self.extract_category_from_url(doc.get('url', ''))
                
                return {
                    'name': title,
                    'brand': brand,
                    'category': category,
                    'price': self.extract_price(doc.get('price', '0')),
                    'description': doc.get('long_description', doc.get('short_description', '')),
                    'usage_instructions': '',  
                    'ingredients': '',  
                    'size': self.extract_size_from_title(title),
                    'stock_quantity': 10, 
                    'url': doc.get('url', '')
                }
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors du parsing du document: {e}")
            return None
        
    def extract_brand_from_title(self, title):
        """Extraire la marque du titre"""
        if not title:
            return "Paralabel"
        
        brands = [
            'FILORGA', 'LA ROCHE POSAY', 'VICHY', 'BIODERMA', 'AVENE', 'EUCERIN',
            'CERAVE', 'NIVEA', 'GARNIER', 'LOREAL', 'MAYBELLINE', 'REVLON',
            'NEUTROGENA', 'CETAPHIL', 'SEBAMED', 'DUCRAY', 'KLORANE', 'LIERAC',
            'CAUDALIE', 'NUXE', 'ROCHE POSAY', 'URIAGE', 'ISDIN', 'NOREVA'
        ]
        
        title_upper = title.upper()
        for brand in brands:
            if brand in title_upper:
                return brand.title()
        
        first_word = title.split()[0] if title.split() else "Paralabel"
        return first_word
    
    def extract_category_from_url(self, url):
        """Extraire la catÃ©gorie de l'URL"""
        if not url:
            return "Soins"
    
        category_mapping = {
        'soin-regard': 'Soins du regard',
        'soin-visage': 'Soins visage',
        'anti-age': 'Soins anti-Ã¢ge',
        'hydratant': 'Soins hydratants',
        'nettoyant': 'Nettoyants',
        'protection-solaire': 'Protection solaire',
        'ecran-solaire': 'Protection solaire',
        'shampoing': 'Soins capillaires',
        'complement': 'ComplÃ©ments alimentaires',
        'vitamine': 'ComplÃ©ments alimentaires',
        'maquillage': 'Maquillage',
        'parfum': 'Parfumerie',
        'bebe': 'Produits bÃ©bÃ©',
        'homme': 'Soins homme'
        }
    
        url_lower = url.lower()
        for keyword, category in category_mapping.items():
            if keyword in url_lower:
               return category
    
        return "Soins et beautÃ©"

    def extract_size_from_title(self, title):
        """Extraire la taille du titre"""
        if not title:
            return ""
        
        import re
        size_patterns = [
            r'(\d+(?:\.\d+)?)\s*ml',
            r'(\d+(?:\.\d+)?)\s*g',
            r'(\d+(?:\.\d+)?)\s*mg',
            r'(\d+)\s*comprimÃ©s?',
            r'(\d+)\s*gÃ©lules?',
            r'(\d+)\s*sachets?'
        ]
        
        title_lower = title.lower()
        for pattern in size_patterns:
            match = re.search(pattern, title_lower)
            if match:
                return match.group(0)
        
        return ""

    def extract_price(self, price_str):
        """Extraire le prix numÃ©rique d'une chaÃ®ne"""
        try:
            if isinstance(price_str, (int, float)):
                return float(price_str)
            
            import re
            price_clean = re.sub(r'[^\d\.,]', '', str(price_str))
            price_clean = price_clean.replace(',', '.')
            
            if price_clean:
                return float(price_clean)
            
            return 0.0
        except:
            return 0.0

    def create_searchable_text(self, product_data):
        """CrÃ©er le texte de recherche pour un produit"""
        parts = []
        
        if product_data.get('name'):
            parts.append(f"Nom: {product_data['name']}")
        if product_data.get('brand'):
            parts.append(f"Marque: {product_data['brand']}")
        if product_data.get('category'):
            parts.append(f"CatÃ©gorie: {product_data['category']}")
        if product_data.get('description'):
            parts.append(f"Description: {product_data['description']}")
        if product_data.get('usage_instructions'):
            parts.append(f"Utilisation: {product_data['usage_instructions']}")
        if product_data.get('ingredients'):
            parts.append(f"IngrÃ©dients: {product_data['ingredients']}")
        
        return " | ".join(parts)

    def insert_product(self, product_data):
        """InsÃ©rer un produit dans la base"""
        cursor = self.conn.cursor()
        
        cursor.execute('''
            INSERT INTO products (name, brand, category, price, description, 
                                usage_instructions, ingredients, size, stock_quantity)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            product_data['name'],
            product_data['brand'],
            product_data['category'],
            product_data['price'],
            product_data['description'],
            product_data['usage_instructions'],
            product_data['ingredients'],
            product_data['size'],
            product_data['stock_quantity']
        ))
        
        return cursor.lastrowid

    def insert_embedding(self, product_id, text_content, embedding):
        """InsÃ©rer un embedding dans la base"""
        cursor = self.conn.cursor()
        
        embedding_blob = pickle.dumps(embedding)
        
        cursor.execute('''
            INSERT INTO product_embeddings (product_id, text_content, embedding)
            VALUES (?, ?, ?)
        ''', (product_id, text_content, embedding_blob))

    def search_database_sqlite(self, query, k=5):
        """Recherche dans SQLite avec similaritÃ© cosinus"""
        logger.info(f"Recherche SQLite pour: {query}")
        
        try:
            query_embedding = self.model.encode([query])[0]
            
            cursor = self.conn.cursor()
            
            cursor.execute('''
                SELECT pe.product_id, pe.text_content, pe.embedding, 
                       p.name, p.brand, p.category, p.price, p.description,
                       p.usage_instructions, p.ingredients, p.size, p.stock_quantity
                FROM product_embeddings pe
                JOIN products p ON pe.product_id = p.id
            ''')
            
            results = cursor.fetchall()
            similarities = []
            
            for row in results:
                try:
                    stored_embedding = pickle.loads(row[2])
                    
                    similarity = self.cosine_similarity(query_embedding, stored_embedding)
                    
                    similarities.append((similarity, row))
                    
                except Exception as e:
                    logger.error(f"Erreur lors du calcul de similaritÃ©: {e}")
                    continue
            
            similarities.sort(key=lambda x: x[0], reverse=True)
            
            passages = []
            for similarity, row in similarities[:k]:
                product_id, text_content, _, name, brand, category, price, description, usage_instructions, ingredients, size, stock_quantity = row
                
                passage = f"""
Produit: {name}
Marque: {brand}
CatÃ©gorie: {category}
Prix: {price} DT
Description: {description}
Utilisation: {usage_instructions}
IngrÃ©dients: {ingredients}
Taille: {size}
Stock: {"Disponible" if stock_quantity > 0 else "Rupture de stock"}
SimilaritÃ©: {similarity:.4f}
                """.strip()
                
                passages.append(passage)
            
            logger.info(f"TrouvÃ© {len(passages)} produits similaires")
            return passages
            
        except Exception as e:
            logger.error(f"Erreur lors de la recherche SQLite: {e}")
            return []

    def cosine_similarity(self, a, b):
        """Calculer la similaritÃ© cosinus entre deux vecteurs"""
        try:
            dot_product = np.dot(a, b)
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)
            
            if norm_a == 0 or norm_b == 0:
                return 0
            
            return dot_product / (norm_a * norm_b)
        except:
            return 0


    def search_database_fallback(self, query, k=5):
        """
        Recherche de fallback utilisant les donnÃ©es rÃ©elles de all_docs.json
        """
        logger.info(f" Recherche fallback pour: {query}")
        
        try:
            json_path = os.path.join("agent AI", "database", "all_docs.json")
            if not os.path.exists(json_path):
                # Essayer d'autres chemins possibles
                possible_paths = [
                    "all_docs.json",
                    "database/all_docs.json",
                    "agent_ai/database/all_docs.json",
                    os.path.join(os.path.dirname(__file__), "database", "all_docs.json")
                ]
                
                for path in possible_paths:
                    if os.path.exists(path):
                        json_path = path
                        break
                else:
                    logger.error("Fichier all_docs.json introuvable")
                    return self._get_no_product_message(query)
            
            with open(json_path, 'r', encoding='utf-8') as f:
                all_docs = json.load(f)
            
            logger.info(f"ğŸ“ ChargÃ© {len(all_docs)} produits depuis all_docs.json")
            
        except Exception as e:
            logger.error(f"Erreur chargement all_docs.json: {e}")
            return self._get_no_product_message(query)
        
        query_lower = query.lower()
        relevant_products = []
        
        for doc in all_docs:
            try:
                score = 0
                title = doc.get('title', '').lower()
                description = doc.get('long_description', doc.get('short_description', '')).lower()
                url = doc.get('url', '').lower()
                
                combined_text = f"{title} {description} {url}"
                
                query_words = [word for word in query_lower.split() if len(word) > 2]
                
                for word in query_words:
                    if word in title:
                        score += 20
                    if word in description:
                        score += 10
                    if word in url:
                        score += 5
                
                if any(keyword in query_lower for keyword in ['ride', 'rides', 'anti-age', 'anti-aging']):
                    if any(keyword in combined_text for keyword in ['anti-age', 'ride', 'fermetÃ©', 'lifting', 'ncef']):
                        score += 50
                
                if any(keyword in query_lower for keyword in ['regard', 'yeux', 'eye', 'contour']):
                    if any(keyword in combined_text for keyword in ['regard', 'eyes', 'contour', 'yeux']):
                        score += 50
                
                if any(keyword in query_lower for keyword in ['hydratant', 'hydration', 'sec', 'sÃ¨che']):
                    if any(keyword in combined_text for keyword in ['hydrat', 'moistur', 'sec']):
                        score += 30
                
                if score > 0:
                    relevant_products.append((doc, score))
                    
            except Exception as e:
                logger.error(f"Erreur lors du scoring du produit: {e}")
                continue
        
        if not relevant_products:
            return self._get_no_product_message(query)
        
        relevant_products.sort(key=lambda x: x[1], reverse=True)
        
        passages = []
        for doc, score in relevant_products[:k]:
            try:
                brand = self.extract_brand_from_title(doc.get('title', ''))
                category = self.extract_category_from_url(doc.get('url', ''))
                size = self.extract_size_from_title(doc.get('title', ''))
                
                passage = f"""
    Produit disponible chez Paralabel:

    Nom: {doc.get('title', 'Produit inconnu')}
    Marque: {brand}
    CatÃ©gorie: {category}
    Prix: {doc.get('price', 'Prix non disponible')}
    Description: {doc.get('long_description', doc.get('short_description', 'Description non disponible'))}
    Conditionnement: {size if size else 'Non spÃ©cifiÃ©'}
    DisponibilitÃ©: En stock chez Paralabel

    Lien produit: {doc.get('url', '')}
    Score de pertinence: {score}
                """.strip()
                
                passages.append(passage)
                
            except Exception as e:
                logger.error(f"Erreur formatage produit: {e}")
                continue
        
        logger.info(f"âœ… Recherche fallback: {len(passages)} produits Paralabel trouvÃ©s")
        return passages

    def _get_no_product_message(self, query):
        """Message quand aucun produit n'est trouvÃ©"""
        return [f"""
    Je suis dÃ©solÃ©, mais je ne trouve pas de produit correspondant Ã  "{query}" dans notre stock actuel chez Paralabel.

    Je vous recommande de :
    â€¢ Visiter notre site web www.paralabel.tn pour voir tous nos produits
    â€¢ Contacter notre pharmacie directement pour vÃ©rifier la disponibilitÃ©
    â€¢ Consulter notre pharmacien pour des conseils personnalisÃ©s

    Notre Ã©quipe sera ravie de vous aider Ã  trouver le produit qui convient le mieux Ã  vos besoins.
        """.strip()]
    def search_database(self, query, k=5):
        """Point d'entrÃ©e principal pour la recherche"""
        if self.db_available:
            try:
                results = self.search_database_sqlite(query, k)
                if results and len(results) > 0:
                    return results
                else:
                    logger.warning("Recherche SQLite sans rÃ©sultats, passage au fallback")
                    return self.search_database_fallback(query, k)
            except Exception as e:
                logger.error(f"Erreur SQLite: {e}, passage au fallback")
                return self.search_database_fallback(query, k)
        else:
            return self.search_database_fallback(query, k)

    def setup_tts(self):
        """Initialisation du systÃ¨me Text-to-Speech"""
        try:
            pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
            logger.info("âœ… SystÃ¨me TTS (pygame) initialisÃ©")
        except Exception as e:
            logger.error(f"âš ï¸ Erreur initialisation TTS (pygame): {e}")
            logger.warning("âš ï¸ TTS non disponible - Mode silencieux activÃ©")

        try:
            import edge_tts
            self.edge_tts_available = True
            logger.info("âœ… Module edge-tts dÃ©tectÃ© - Voix arabe activÃ©e")
        except ImportError:
            self.edge_tts_available = False
            logger.warning("âš ï¸ edge-tts non disponible - Lecture vocale arabe dÃ©sactivÃ©e. Installer avec: pip install edge-tts")


    def setup_language_patterns(self):
        """Configuration des patterns de langue amÃ©liorÃ©s"""
        self.language_patterns = {
            'arabic': {
                'keywords': [
                    r'(Ø£Ù‡Ù„Ø§|Ø§Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù…|Ø¹Ø³Ù„Ø§Ù…Ø©|ÙŠØ²ÙŠÙƒ|ÙŠØ§|ÙƒÙŠÙ|Ø´Ù„ÙˆÙ†Ùƒ|Ø§Ø­ÙˆØ§Ù„Ùƒ|Ù„Ø§Ø¨Ø§Ø³|Ø´Ù†Ø­ÙˆØ§Ù„Ùƒ)',
                    r'(ØµØ¨Ø§Ø­|Ù…Ø³Ø§Ø¡|Ù„ÙŠÙ„Ø©|Ù†Ù‡Ø§Ø±)(\s)?(Ø§Ù„Ø®ÙŠØ±|Ø·ÙŠØ¨Ø©|Ø²ÙŠÙ†)',
                    r'(Ø¨ÙˆÙ†Ø¬ÙˆØ±|Ø¨ÙˆÙ†Ø³ÙˆØ§Ø±|Ø³Ø§Ù„ÙŠ|Ù‡Ø§ÙŠ)',
                    r'(Ø´Ù†Ùˆ|Ø§ÙŠØ´|Ø´ÙŠØ§|ÙˆÙŠÙ†Ùˆ|ÙƒÙŠÙØ§Ø´|Ø¹Ù„Ø§Ø´|ÙˆÙ‚ØªØ§Ø´|Ù‚Ø¯Ø§Ø´|Ø¨Ù‚Ø¯Ø§Ø´|Ø¨ÙƒØ¯Ø§Ø´)',
                    r'(ØªÙ†Ø¬Ù…|Ù‚Ø§Ø¯Ø±|Ù…Ù…ÙƒÙ†|ÙŠÙ…ÙƒÙ†)(\s)?(ØªØ¹Ø§ÙˆÙ†Ù†ÙŠ|ØªØ³Ø§Ø¹Ø¯Ù†ÙŠ|ØªÙ‚ÙˆÙ„ÙŠ)',
                    r'(Ø§Ù†Ø§|Ø§Ù†ÙŠ)(\s)?(Ù†Ø­Ø¨|Ù†Ø­ØªØ§Ø¬|Ù†Ø¨ØºÙŠ|Ù†Ø±ÙŠØ¯)',
                    r'(Ù‚ÙˆÙ„ÙŠ|ÙÙ‡Ù…Ù†ÙŠ|ÙˆØ¶Ø­Ù„ÙŠ|Ø´Ø±Ø­Ù„ÙŠ)',
                    r'(Ø´ÙƒØ±Ø§|Ù…Ø±Ø³ÙŠ|ÙŠØ¹Ø·ÙŠÙƒ|Ø§Ù„Ù„Ù‡|Ø¨Ø±Ø´Ø§)',
                    r'(ÙƒØ±ÙŠÙ…|ÙƒØ±Ø§Ù…|ÙƒØ±ÙŠÙ…Ø©|ÙˆØ§Ù‚ÙŠ|Ø´Ù…Ø³|Ø­Ù…Ø§ÙŠØ©)',
                    r'(Ø¯ÙˆØ§|Ø¯ÙˆØ§Ø¡|Ø¹Ù„Ø§Ø¬)',
                    r'(Ø´Ø§Ù…Ø¨Ùˆ|Ø´Ø§Ù…Ø¨ÙˆØ§Ù†|Ø´Ù…Ø¨ÙˆØ§Ù†)',
                    r'(ØµØ§Ø¨ÙˆÙ†|Ø³Ø§ÙÙˆÙ†)',
                    r'(Ø¹Ø·Ø±|Ø¨Ø±ÙØ§Ù†|Ø¨Ø±ÙÙˆÙ…)',
                    r'(Ø¯ÙˆØ¯ÙˆØ±Ø§Ù†|Ø¯ÙŠÙˆØ¯ÙˆØ±Ø§Ù†)',
                    r'(ÙÙŠØªØ§Ù…ÙŠÙ†|ÙÙŠØªØ§Ù…ÙŠÙ†Ø©)',
                    r'(Ø§Ù„Ø³Ø¹Ø±|Ø§Ù„Ø«Ù…Ù†|Ø§Ù„ÙƒÙ„ÙØ©|Ø¨Ù‚Ø¯Ø§Ø´)',
                    r'(Ø¨Ø±Ø´Ø§|ÙŠØ§Ø³Ø±|ÙÙ…Ø§|Ù…Ø§ÙƒØ§Ù†|Ø²Ø§Ø¯Ø©|ÙƒÙŠÙ…Ø§|Ù‡ÙƒØ§|Ù‡ÙƒØ©)',
                    r'(Ø¹Ù†Ø¯ÙƒÙ…|ÙÙŠÙ‡|Ù…ÙˆØ¬ÙˆØ¯|Ù…ØªØ§Ø¹)',
                    r'(Ø¨Ø´Ø±Ø©|ÙˆØ¬Ù‡|Ø´Ø¹Ø±|Ù…Ø®ØªÙ„Ø·|Ø¯Ù‡Ù†ÙŠ|Ø¬Ø§Ù)',
                ],
                'tts_lang': 'ar',
                'greeting_responses': [
                    "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØµÙŠØ¯Ù„ÙŠØ© Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„ØŸ",
                    "Ù…Ø±Ø­Ø¨Ø§! Ù„Ø§Ø¨Ø§Ø³ØŸ ØªÙ†Ø¬Ù… ØªØ³Ø£Ù„Ù†ÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù†ØªØ¬ Ø£Ùˆ Ø¯ÙˆØ§Ø¡ ØªØ­ØªØ§Ø¬Ù‡.",
                    "ÙŠØ§ Ù‡Ù„Ø§! ÙƒÙŠÙØ§Ø´ Ù†Ø¬Ù…Øª Ù†Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ",
                    "Ø£Ù‡Ù„Ø§ Ø¨ÙŠÙƒ ÙÙŠ ØµÙŠØ¯Ù„ÙŠØ© Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„! Ø´Ù†Ø­ÙˆØ§Ù„ÙƒØŸ"
                ],
                'thanks_responses': [
                    "Ø§Ù„Ø¹ÙÙˆ! Ø£ÙŠ ÙˆÙ‚Øª ØªØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø£Ù†Ø§ Ù‡Ù†Ø§.",
                    "Ù„Ø§ Ø´ÙƒØ± Ø¹Ù„Ù‰ ÙˆØ§Ø¬Ø¨! Ø¹Ù†Ø¯Ùƒ Ø­Ø§Ø¬Ø© Ø£Ø®Ø±Ù‰ØŸ",
                    "ØªØ³Ù„Ù…! Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Øª Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŒ Ø£Ù†Ø§ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©."
                ],
                'general_responses': [
                    "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ ØµÙŠØ¯Ù„ÙŠØ© Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„. ØªÙ†Ø¬Ù… ØªØ³Ø£Ù„Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŒ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠÙ„ÙŠØ©ØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙˆÙ†ØµØ§Ø¦Ø­ ØµØ­ÙŠØ©.",
                    "Ù†Ø¬Ù…Øª Ù†Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŒ Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø¹Ù†Ø§ÙŠØ©ØŒ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø±."
                ]
            },
            
            'french': {
                'keywords': [
                    r'(salut|bonjour|bonsoir|hello|salaam|coucou|bonne\s+journÃ©e)',
                    r'(comment|ca|Ã§a)(\s)?(va|allez|vous\s+portez)',
                    r'(bonne|bon)(\s)?(journÃ©e|matinÃ©e|soirÃ©e|nuit)',
                    r'(que|quoi|comment|pourquoi|quand|oÃ¹|combien|quel|quelle)',
                    r'(pouvez|peux|peut|pourriez)(\s)?(vous|tu)(\s)?(m\'|me|nous)',
                    r'(j\'ai|je\s+veux|je\s+cherche|je\s+voudrais|j\'aimerais)',
                    r'(dites|expliquez|montrez|aidez|proposez|recommandez)',
                    r'(merci|thanks|remercie|je\s+vous\s+remercie)',
                    r'(crÃ¨me|gel|shampoing|savon|parfum|dÃ©odorant|mÃ©dicament|Ã©cran|solaire)',
                    r'(vitamine|complÃ©ment|paracÃ©tamol|aspirine|sirop|protection|spf)',
                    r'(prix|coÃ»t|combien|euros?|dinars?)',
                    r'(tube|flacon|boÃ®te|ml|grammes?)',
                    r'(est-ce\s+que|qu\'est-ce\s+que|avez-vous|y\s+a-t-il)',
                    r'(s\'il\s+vous\s+plaÃ®t|svp|merci\s+beaucoup)',
                    r'(peau|visage|cheveux|mixte|grasse|sÃ¨che|sensible)',
                ],
                'tts_lang': 'fr',
                'greeting_responses': [
                    "Bonjour ! Comment puis-je vous aider Ã  la pharmacie Paralabel aujourd'hui ?",
                    "Salut ! Je suis lÃ  pour rÃ©pondre Ã  vos questions sur nos mÃ©dicaments et produits.",
                    "Bonsoir ! Que puis-je faire pour vous ?",
                ],
                'thanks_responses': [
                    "De rien ! N'hÃ©sitez pas si vous avez d'autres questions.",
                    "Je vous en prie ! Je reste Ã  votre disposition.",
                    "Avec plaisir ! Y a-t-il autre chose ?"
                ],
                'general_responses': [
                    "Je suis votre assistant virtuel Paralabel. Je peux vous renseigner sur les mÃ©dicaments, produits cosmÃ©tiques, prix et conseils santÃ©.",
                    "Je suis lÃ  pour vous aider avec tous vos besoins en pharmacie et parapharmacie."
                ]
            },
            
            'english': {
                'keywords': [
                    r'(hello|hi|hey|good\s+morning|good\s+evening|good\s+afternoon)',
                    r'(how\s+are\s+you|how\s+do\s+you\s+do|what\'s\s+up|how\'s\s+it\s+going)',
                    r'(nice\s+to\s+meet|pleased\s+to\s+meet|have\s+a\s+good\s+day)',
                    r'(what|how|why|when|where|which|who|whose)',
                    r'(can\s+you|could\s+you|would\s+you|will\s+you|do\s+you)',
                    r'(i\s+want|i\s+need|i\'m\s+looking|i\s+would\s+like|i\'d\s+like)',
                    r'(tell\s+me|show\s+me|explain|help|assist|recommend|suggest)',
                    r'(thank\s+you|thanks|appreciate|grateful)',
                    r'(cream|gel|shampoo|soap|perfume|deodorant|medicine|sunscreen)',
                    r'(vitamin|supplement|paracetamol|aspirin|syrup|protection|spf)',
                    r'(price|cost|how\s+much|dollars?|euros?)',
                    r'(tube|bottle|box|ml|grams?)',
                    r'(do\s+you\s+have|is\s+there|are\s+there|please|excuse\s+me)',
                    r'(skin|face|hair|combination|oily|dry|sensitive)',
                ],
                'tts_lang': 'en',
                'greeting_responses': [
                    "Hello! How can I help you at Paralabel pharmacy today?",
                    "Hi there! I'm here to assist with your medication and product questions.",
                    "Good day! What can I do for you?",
                    "Hello and welcome to Paralabel! How are you doing?"
                ],
                'thanks_responses': [
                    "You're welcome! Feel free to ask if you have more questions.",
                    "My pleasure! I'm here if you need anything else.",
                    "Glad to help! Is there anything else you'd like to know?"
                ],
                'general_responses': [
                    "I'm your Paralabel virtual assistant. I can help with medications, cosmetic products, prices and health advice.",
                    "I'm here to assist with all your pharmacy and parapharmacy needs."
                ]
            }
        }

    def detect_language_advanced(self, text):
        """DÃ©tection de langue amÃ©liorÃ©e - VERSION CORRIGÃ‰E"""
        if not text or len(text.strip()) == 0:
            return 'french'

        text_clean = text.lower().strip()
        
        # ğŸ”¹ DÃ©tection des caractÃ¨res arabes
        arabic_chars = len(re.findall(r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]', text))
        if arabic_chars > 2:
            logger.info(f"CaractÃ¨res arabes dÃ©tectÃ©s: {arabic_chars}")
            return 'arabic'

        # ğŸ”¹ Score par langue basÃ© sur mots-clÃ©s
        language_scores = {'arabic': 0, 'french': 0, 'english': 0}
        
        # Mots-clÃ©s spÃ©cifiques aux produits et questions
        enhanced_patterns = {
            'arabic': [
                r'(Ø¹Ù†Ø¯ÙƒÙ…|ÙÙŠÙ‡|Ù…ÙˆØ¬ÙˆØ¯|ØªÙ†Ø¬Ù…ÙˆØ§|ÙˆÙŠÙ†Ùˆ|ÙƒÙŠÙØ§Ø´|Ø´Ù†Ùˆ|Ø§ÙŠØ´)',
                r'(ÙƒØ±ÙŠÙ…|Ø´Ø§Ù…Ø¨Ùˆ|Ø¯ÙˆØ§|Ø¯ÙˆØ§Ø¡|ÙˆØ§Ù‚ÙŠ|Ø´Ù…Ø³|Ø¹Ø·Ø±|ÙÙŠØªØ§Ù…ÙŠÙ†|Ø³ÙŠØ±ÙˆÙ…)',
                r'(Ø¨Ù‚Ø¯Ø§Ø´|Ø¨ÙƒØ¯Ø§Ø´|Ø§Ù„Ø³Ø¹Ø±|Ø§Ù„Ø«Ù…Ù†|Ø¯ÙŠÙ†Ø§Ø±)',
                r'(Ø¨Ø´Ø±Ø©|ÙˆØ¬Ù‡|Ø´Ø¹Ø±|Ø¯Ù‡Ù†ÙŠ|Ø¬Ø§Ù|Ù…Ø®ØªÙ„Ø·)',
                r'(Ø§Ù‚ØªØ±Ø­ÙˆÙ„ÙŠ|Ø§Ù†ØµØ­ÙˆÙ†ÙŠ|Ù‚ÙˆÙ„ÙˆÙ„ÙŠ)',
                r'(Ø£Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù…|Ø´ÙƒØ±Ø§|Ù…Ø±Ø³ÙŠ)'
            ],
            'french': [
                r'(avez-vous|proposez|recommandez|conseillez|suggÃ©rez)',
                r'(crÃ¨me|Ã©cran|solaire|shampoing|mÃ©dicament|parfum|vitamine|sÃ©rum)',
                r'(combien|prix|coÃ»t|euros?|dinars?)',
                r'(peau|visage|cheveux|grasse|sÃ¨che|mixte|sensible)',
                r'(propositions|suggestions|conseils|produits)',
                r'(bonjour|salut|bonsoir|merci|merci\s+beaucoup)',
                r'(pour\s+peau|anti-Ã¢ge|protection|hydratant)',
                r'(quelles?|quel|que|comment|oÃ¹|pourquoi)'
            ],
            'english': [
                r'(do\s+you\s+have|recommend|suggest|propose)',
                r'(cream|sunscreen|shampoo|medicine|perfume|vitamin|serum)',
                r'(how\s+much|price|cost|dollars?)',
                r'(skin|face|hair|oily|dry|combination|sensitive)',
                r'(products|suggestions|recommendations)',
                r'(hello|hi|good\s+morning|thank\s+you)',
                r'(for\s+skin|anti-aging|protection|moisturizing)',
                r'(what|how|where|why|which)'
            ]
        }
        
        for lang, patterns in enhanced_patterns.items():
            for pattern in patterns:
                matches = len(re.findall(pattern, text_clean, re.IGNORECASE))
                if matches > 0:
                    language_scores[lang] += matches * 3

        # ğŸ”¹ DÃ©tection automatique avec langdetect
        try:
            from langdetect import detect
            detected = detect(text_clean)
            if detected == 'fr':
                language_scores['french'] += 3
            elif detected == 'en':
                language_scores['english'] += 3
            elif detected == 'ar':
                language_scores['arabic'] += 3
        except:
            pass
        
        # ğŸ”¹ Bonus pour certains patterns caractÃ©ristiques
        if re.search(r'(qu\'est-ce|est-ce\s+que)', text_clean, re.IGNORECASE):
            language_scores['french'] += 5
        elif re.search(r'(what\'s|how\'s|don\'t|can\'t)', text_clean, re.IGNORECASE):
            language_scores['english'] += 5

        # ğŸ”¹ Retourner la langue avec le meilleur score
        if max(language_scores.values()) > 0:
            detected_lang = max(language_scores, key=language_scores.get)
            logger.info(f"Langue dÃ©tectÃ©e: {detected_lang} (scores: {language_scores})")
            return detected_lang
        
        # Par dÃ©faut, franÃ§ais
        return 'french'
    def is_greeting_or_simple_query(self, text, language):
        """DÃ©tecte UNIQUEMENT les salutations PURES et questions simples - VERSION CORRIGÃ‰E"""
        if not text:
            return False, None

        text_clean = text.lower().strip()
        
        product_question_patterns = {
            'arabic': [
                r'(Ø¹Ù†Ø¯ÙƒÙ…|ÙÙŠÙ‡|Ù…ÙˆØ¬ÙˆØ¯|ØªÙ†Ø¬Ù…ÙˆØ§|Ù‚ÙˆÙ„ÙˆÙ„ÙŠ|ÙˆÙŠÙ†Ùˆ|ÙƒÙŠÙØ§Ø´)',
                r'(ÙƒØ±ÙŠÙ…|Ø´Ø§Ù…Ø¨Ùˆ|Ø¯ÙˆØ§|Ø¯ÙˆØ§Ø¡|ÙˆØ§Ù‚ÙŠ|Ø´Ù…Ø³|Ø¹Ø·Ø±|ÙÙŠØªØ§Ù…ÙŠÙ†)',
                r'(Ø¨Ù‚Ø¯Ø§Ø´|Ø¨ÙƒØ¯Ø§Ø´|Ø§Ù„Ø³Ø¹Ø±|Ø§Ù„Ø«Ù…Ù†)',
                r'(Ø¨Ø´Ø±Ø©|ÙˆØ¬Ù‡|Ø´Ø¹Ø±|Ø¯Ù‡Ù†ÙŠ|Ø¬Ø§Ù|Ù…Ø®ØªÙ„Ø·)',
                r'(Ø§Ù‚ØªØ±Ø­ÙˆÙ„ÙŠ|Ø§Ù†ØµØ­ÙˆÙ†ÙŠ|Ø´Ù†Ùˆ|Ø§ÙŠØ´|Ø´ÙŠØ§)'
            ],
            'french': [
                r'(avez-vous|proposez|recommandez|conseillez|suggÃ©rez|cherche|veux|voudrais|aimerais)',
                r'(crÃ¨me|Ã©cran|solaire|shampoing|mÃ©dicament|parfum|vitamine|sÃ©rum|gel)',
                r'(combien|prix|coÃ»t|coÃ»te)',
                r'(peau|visage|cheveux|grasse|sÃ¨che|mixte|sensible)',
                r'(propositions|suggestions|conseils|produits|gamme)',
                r'(pour\s+(peau|visage|cheveux)|anti-|protection|hydratant)'
            ],
            'english': [
                r'(do\s+you\s+have|recommend|suggest|propose|looking\s+for|want|need)',
                r'(cream|sunscreen|shampoo|medicine|perfume|vitamin|serum|gel)',
                r'(how\s+much|price|cost)',
                r'(skin|face|hair|oily|dry|combination|sensitive)',
                r'(products|suggestions|recommendations|options)',
                r'(for\s+(skin|face|hair)|anti-|protection|moisturizing)'
            ]
        }
        
        for pattern in product_question_patterns.get(language, product_question_patterns['french']):
            if re.search(pattern, text_clean, re.IGNORECASE):
                return False, None
        
        thanks_patterns = {
            'arabic': [r'^(Ø´ÙƒØ±Ø§|Ù…Ø±Ø³ÙŠ|ÙŠØ¹Ø·ÙŠÙƒ\s+Ø§Ù„ØµØ­Ø©)(\s+Ø¨Ø±Ø´Ø§)?$'],
            'french': [r'^(merci|merci\s+beaucoup|je\s+vous\s+remercie)(\s+.*)?$'],
            'english': [r'^(thank\s+you|thanks|thank\s+you\s+very\s+much)(\s+.*)?$']
        }

        for pattern in thanks_patterns.get(language, thanks_patterns['french']):
            if re.search(pattern, text_clean, re.IGNORECASE):
                return True, 'thanks'

        pure_greeting_patterns = {
            'arabic': [
                r'^(Ø£Ù‡Ù„Ø§|Ø§Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù…\s+Ø¹Ù„ÙŠÙƒÙ…|Ø¹Ø³Ù„Ø§Ù…Ø©)(\s*[!.?]?\s*)?$',
                r'^(ØµØ¨Ø§Ø­|Ù…Ø³Ø§Ø¡)\s+(Ø§Ù„Ø®ÙŠØ±|Ø·ÙŠØ¨Ø©)(\s*[!.?]?\s*)?$',
                r'^(ÙŠØ§\s+Ù‡Ù„Ø§|Ù‡Ø§ÙŠ|Ø³Ø§Ù„ÙŠ)(\s*[!.?]?\s*)?$',
                r'^(ÙƒÙŠÙÙƒ|Ø´Ù„ÙˆÙ†Ùƒ|Ø§Ø­ÙˆØ§Ù„Ùƒ|Ù„Ø§Ø¨Ø§Ø³|Ø´Ù†Ø­ÙˆØ§Ù„Ùƒ)(\s*[!.?]?\s*)?$'
            ],
            'french': [
                r'^(bonjour|salut|bonsoir|hello|coucou)(\s*[!.?]?\s*)?$',
                r'^(bonne?\s+(journÃ©e|matinÃ©e|soirÃ©e|nuit))(\s*[!.?]?\s*)?$',
                r'^(comment\s+(Ã§a\s+va|allez-vous))(\s*[!.?]?\s*)?$',
                r'^(Ã§a\s+va)(\s*[!.?]?\s*)?$'
            ],
            'english': [
                r'^(hello|hi|hey)(\s*[!.?]?\s*)?$',
                r'^(good\s+(morning|evening|afternoon))(\s*[!.?]?\s*)?$',
                r'^(how\s+are\s+you|what\'s\s+up|how\'s\s+it\s+going)(\s*[!.?]?\s*)?$'
            ]
        }

        for pattern in pure_greeting_patterns.get(language, pure_greeting_patterns['french']):
            if re.search(pattern, text_clean, re.IGNORECASE):
                return True, 'greeting'

        greeting_with_question_patterns = {
            'french': [
                r'^(bonjour|salut|bonsoir)\s*,?\s+.{10,}',  # Salutation + texte long
                r'^(bonjour|salut|bonsoir)\s*,?\s+(quel|que|comment|combien|avez|proposez)'
            ],
            'arabic': [
                r'^(Ø£Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù…)\s*,?\s+.{10,}',
                r'^(Ø£Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù…)\s*,?\s+(Ø´Ù†Ùˆ|Ø§ÙŠØ´|ÙƒÙŠÙ|Ø¹Ù†Ø¯ÙƒÙ…)'
            ],
            'english': [
                r'^(hello|hi|good\s+morning)\s*,?\s+.{10,}',
                r'^(hello|hi|good\s+morning)\s*,?\s+(what|how|do\s+you|can\s+you)'
            ]
        }
        
        for pattern in greeting_with_question_patterns.get(language, greeting_with_question_patterns['french']):
            if re.search(pattern, text_clean, re.IGNORECASE):
                return False, None  
        return False, None


    def generate_simple_response(self, response_type, language):
        """GÃ©nÃ¨re une rÃ©ponse simple pour les salutations"""
        import random
        
        responses = self.language_patterns[language].get(f'{response_type}_responses', [])
        if responses:
            return random.choice(responses)
        
        if response_type == 'greeting':
            if language == 'arabic':
                return "Ø£Ù‡Ù„Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"
            elif language == 'english':
                return "Hello! How can I help you?"
            else:
                return "Bonjour ! Comment puis-je vous aider ?"
        elif response_type == 'thanks':
            if language == 'arabic':
                return "Ø§Ù„Ø¹ÙÙˆ! Ø£ÙŠ ÙˆÙ‚Øª."
            elif language == 'english':
                return "You're welcome!"
            else:
                return "De rien !"


    def generate_response(self, question, context_passages, language='french'):
        """GÃ©nÃ©ration de rÃ©ponse multilingue STRICTE avec Gemini - VERSION CORRIGÃ‰E"""
        logger.info(f"Question reÃ§ue : {question} (langue: {language})")

        # ğŸ”¹ SEULEMENT pour les vraies salutations pures
        is_simple, response_type = self.is_greeting_or_simple_query(question, language)
        if is_simple:
            simple_response = self.generate_simple_response(response_type, language)
            logger.info(f"RÃ©ponse simple gÃ©nÃ©rÃ©e : {simple_response}")
            return simple_response

        # ğŸ”¹ Pour toutes les autres questions, traitement complet
        context_text = "\n\n".join(context_passages) if context_passages else ""
        
        # ğŸ”¸ Prompts amÃ©liorÃ©s avec meilleure dÃ©tection des questions produits
        prompts = {
            'arabic': f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØµÙˆØªÙŠ Ù„ØµÙŠØ¯Ù„ÙŠØ© Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„ ÙÙ‚Ø·. Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„ØªÙˆÙ†Ø³ÙŠØ©.

    ğŸ”¹ Ø§Ù„Ø³Ø¤Ø§Ù„:
    {question}

    ğŸ”¸ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„ ÙÙ‚Ø·:
    {context_text}

    âš ï¸ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:
    - Ø§Ø³ØªØ¹Ù…Ù„ ÙÙ‚Ø· Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡
    - Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…Ù†ØªØ¬ Ù…Ù†Ø§Ø³Ø¨ØŒ Ø§Ø¹ØªØ°Ø± ÙˆÙ‚Ù„ Ø£Ù†Ù‡ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹
    - Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ù†ØªØ¬Ø§Øª Ø£Ùˆ Ø£Ø³Ø¹Ø§Ø±
    - Ù„Ø§ ØªØ°ÙƒØ± Ù…Ù†ØªØ¬Ø§Øª Ù…Ù† ØµÙŠØ¯Ù„ÙŠØ§Øª Ø£Ø®Ø±Ù‰
    - ÙƒÙ† ØµØ§Ø¯Ù‚ Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨

    ğŸŸ¢ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„ØªÙˆÙ†Ø³ÙŠ:""",

            'french': f"""Tu es l'assistant vocal de la pharmacie Paralabel UNIQUEMENT. 

    ğŸ”¹ Question du client :
    {question}

    ğŸ”¸ Produits RÃ‰ELLEMENT disponibles chez Paralabel :
    {context_text}

    âš ï¸ Instructions STRICTES :
    - Utilise UNIQUEMENT les produits listÃ©s ci-dessus
    - Si aucun produit ne correspond, excuse-toi et dis qu'il n'est pas disponible actuellement
    - Ne JAMAIS inventer de produits, prix ou marques
    - Ne JAMAIS mentionner de produits d'autres pharmacies
    - Sois honnÃªte si le produit demandÃ© n'existe pas dans notre stock

    âœ… Si des produits correspondent :
    - PrÃ©sente les options disponibles chez Paralabel
    - Mentionne les marques, prix et caractÃ©ristiques
    - Donne des conseils d'utilisation si pertinent

    âŒ Si aucun produit ne correspond exactement :
    "Je suis dÃ©solÃ©, nous n'avons pas ce type de produit en stock actuellement chez Paralabel. Je vous invite Ã  consulter notre pharmacien sur place ou Ã  nous contacter pour plus d'informations sur nos arrivages."

    ğŸŸ¢ RÃ©ponse professionnelle et honnÃªte :""",

            'english': f"""You are the voice assistant for Paralabel pharmacy ONLY.

    ğŸ”¹ Customer question:
    {question}

    ğŸ”¸ Products ACTUALLY available at Paralabel:
    {context_text}

    âš ï¸ STRICT Instructions:
    - Use ONLY the products listed above
    - If no product matches, apologize and say it's not currently available
    - NEVER invent products, prices or brands
    - NEVER mention products from other pharmacies
    - Be honest if the requested product doesn't exist in our stock

    âœ… If products match:
    - Present available options at Paralabel
    - Mention brands, prices and features
    - Give usage advice if relevant

    âŒ If no product matches exactly:
    "I'm sorry, we don't currently have this type of product in stock at Paralabel. Please visit our pharmacy or contact us for information about new arrivals."

    ğŸŸ¢ Professional and honest answer:"""
        }

        try:
            prompt = prompts.get(language, prompts['french'])
            response = self.gemini_model.generate_content(prompt)
            generated_response = response.text.strip()
            
            logger.info(f"RÃ©ponse gÃ©nÃ©rÃ©e: {generated_response}")
            return generated_response

        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse: {e}")
            error_responses = {
                'arabic': "Ø¢Ø³ÙØŒ Ù…Ø§ Ù‚Ø¯Ø±ØªØ´ Ù†Ø¬Ø§ÙˆØ¨. Ø¬Ø±Ø¨ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
                'french': "DÃ©solÃ©, je n'ai pas pu gÃ©nÃ©rer de rÃ©ponse. Veuillez rÃ©essayer.",
                'english': "Sorry, I couldn't generate a response. Please try again."
            }
            return error_responses.get(language, error_responses['french'])

    def text_to_speech(self, text, language='french'):
        """Convertit le texte en parole dans la langue appropriÃ©e"""
        try:
            if not hasattr(pygame.mixer, 'music'):
                logger.warning("TTS non disponible - pygame non initialisÃ©")
                return False

            logger.info(f" TTS en {language} pour: {text[:50]}...")

            if language.lower() == 'arabic':
                async def speak_with_edge():
                    try:
                        voice = "ar-TN-HediNeural"  # Voix arabe tunisienne (ou "ar-SA", etc.)
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
                            temp_path = tmp_file.name

                        communicate = edge_tts.Communicate(text=text, voice=voice)
                        await communicate.save(temp_path)

                        pygame.mixer.music.load(temp_path)
                        pygame.mixer.music.play()
                        while pygame.mixer.music.get_busy():
                            await asyncio.sleep(0.1)

                        os.unlink(temp_path)
                        logger.info("âœ… Lecture audio avec edge-tts rÃ©ussie")
                        return True
                    except Exception as e:
                        logger.error(f"âš ï¸ Erreur TTS (edge-tts): {e}")
                        return False

                return asyncio.run(speak_with_edge())

            else:
                tts_lang_map = {
                    'french': 'fr',
                    'english': 'en'
                }
                tts_lang = tts_lang_map.get(language.lower(), 'fr')

                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
                    temp_path = tmp_file.name

                tts = gTTS(text=text, lang=tts_lang, slow=False)
                tts.save(temp_path)

                pygame.mixer.music.load(temp_path)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)

                os.unlink(temp_path)
                logger.info("âœ… Lecture audio avec gTTS rÃ©ussie")
                return True

        except Exception as e:
            logger.error(f"âš ï¸ Erreur globale TTS: {e}")
            return False

        
    def preprocess_audio(self, audio_path):
        """PrÃ©traitement audio amÃ©liorÃ©"""
        try:
            if audio_path.lower().endswith(".mp3"):
                logger.info("Conversion MP3 vers WAV...")
                mp3_audio = AudioSegment.from_mp3(audio_path)
                audio_path_wav = "converted.wav"
                mp3_audio.export(audio_path_wav, format="wav")
                audio_path = audio_path_wav

            audio, sr = librosa.load(audio_path, sr=16000)

            audio_clean = nr.reduce_noise(y=audio, sr=sr)

            audio_clean = audio_clean / np.max(np.abs(audio_clean))

            processed_path = "temp_processed.wav"
            write(processed_path, sr, (audio_clean * 32767).astype(np.int16))

            logger.info("PrÃ©traitement audio terminÃ©")
            return processed_path
        except Exception as e:
            logger.error(f"Erreur lors du prÃ©traitement audio: {e}")
            return audio_path

    def record_audio(self, duration=5, samplerate=16000):
        """Enregistrement audio"""
        logger.info(" DÃ©marrage de l'enregistrement...")
        try:
            recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')
            sd.wait()
            
            recording = recording / np.max(np.abs(recording))
            
            audio_path = "temp.wav"
            write(audio_path, samplerate, (recording * 32767).astype(np.int16))
            logger.info("âœ… Enregistrement terminÃ©")
            return audio_path
        except Exception as e:
            logger.error(f"âš ï¸ Erreur lors de l'enregistrement: {e}")
            raise

    def transcribe_audio_multilingual(self, audio_path):
        """Transcription multilingue amÃ©liorÃ©e"""
        try:
            processed_audio = self.preprocess_audio(audio_path)
            
            result = self.whisper_model.transcribe(
                processed_audio,
                language=None,
                task="transcribe",
                temperature=0.0,
                beam_size=5,
                best_of=5,
                no_speech_threshold=0.6,
                logprob_threshold=-1.0,
                compression_ratio_threshold=2.4,
                condition_on_previous_text=False
            )
            
            text = result.get("text", "").strip()
            detected_lang_whisper = result.get("language", "")
            
            logger.info(f"Whisper dÃ©tectÃ©: {detected_lang_whisper}, Texte: {text}")
            
            corrected_text = self.post_process_transcription(text)
            
            if processed_audio != audio_path and os.path.exists(processed_audio):
                os.remove(processed_audio)
                
            return corrected_text
            
        except Exception as e:
            logger.error(f"âš ï¸ Erreur lors de la transcription: {e}")
            return ""

    def post_process_transcription(self, text):
        """Post-traitement avec corrections spÃ©cifiques"""
        if not text:
            return ""
            
        corrections = [
            (r'la roche posay|laroche posay|la roche-posay', 'La Roche-Posay'),
            (r'eucerin|eucÃ©rin|eucerine', 'Eucerin'),
            (r'bioderma|bio derma', 'Bioderma'),
            (r'vichy|vichi|vishy', 'Vichy'),
            (r'avÃ¨ne|avene|aven', 'AvÃ¨ne'),
            (r'cerave|cera ve|sera ve', 'CeraVe'),
            (r'nivea|nivÃ©a', 'Nivea'),
            (r'garnier|garnyÃ©', 'Garnier'),
            (r'loreal|l\'oreal|l\'orÃ©al', "L'OrÃ©al"),
            
            (r'ÙƒØ±ÙŠÙ…|krim|krym', 'crÃ¨me'),
            (r'Ø´Ø§Ù…Ø¨Ùˆ|Ø´Ø§Ù…Ø¨ÙˆØ§Ù†|shampo', 'shampoing'),
            (r'Ø³ÙŠØ±ÙˆÙ…|sirum|sÃ©rom', 'sÃ©rum'),
            (r'Ø¬ÙŠÙ„|jil', 'gel'),
            (r'Ù…Ø§Ø³Ùƒ|mask', 'masque'),
            (r'Ø¨Ø±ÙØ§Ù†|Ø¨Ø±ÙÙˆÙ†|parfon', 'parfum'),
            (r'Ø¯ÙˆØ¯ÙˆØ±Ø§Ù†|deodoran', 'dÃ©odorant'),
            (r'ØµØ§Ø¨ÙˆÙ†|saboun', 'savon'),
            (r'ÙÙŠØªØ§Ù…ÙŠÙ†|vitamin', 'vitamine'),
            (r'Ø¯ÙˆØ§|Ø¯ÙˆØ§Ø¡', 'mÃ©dicament'),
            (r'ÙˆØ§Ù‚ÙŠ\s+Ø´Ù…Ø³|Ã©cran\s+solaire', 'Ã©cran solaire'),
            
            (r'Ø¨Ù‚Ø¯Ø§Ø´|Ø¨ÙƒØ¯Ø§Ø´|b9adesh', 'combien'),
            (r'Ø§Ù„Ø³Ø¹Ø±|Ø§Ù„Ø«Ù…Ù†|prix', 'prix'),
            (r'Ø¯ÙŠÙ†Ø§Ø±|dinar', 'dinar'),
            (r'ÙŠÙˆØ±Ùˆ|euro', 'euro'),
            (r'Ù…Ù„|ml', 'ml'),
            (r'ØºØ±Ø§Ù…|Ø¬Ø±Ø§Ù…|gram', 'gramme'),
            
            (r'paralabel|para label|Ø¨Ø§Ø±Ø§Ù„Ø§Ø¨Ù„', 'Paralabel'),
            (r'ØµÙŠØ¯Ù„ÙŠØ©|pharmacie|pharmacy', 'pharmacie'),
        ]
        
        corrected_text = text
        for pattern, replacement in corrections:
            corrected_text = re.sub(pattern, replacement, corrected_text, flags=re.IGNORECASE)
        
        corrected_text = re.sub(r'\s+', ' ', corrected_text).strip()
        
        return corrected_text

    def handle_command(self, command_json):
        """Gestionnaire de commandes principal"""
        try:
            command = json.loads(command_json)
            
            if command["cmd"] == "process_audio":
                start_time = time.time()
                logger.info(" DÃ©marrage du traitement audio")
                
                audio_file = self.record_audio()
                question = self.transcribe_audio_multilingual(audio_file)
                
                if not question:
                    error_msg = "DÃ©solÃ©, je n'ai pas pu comprendre votre question."
                    self.text_to_speech(error_msg, 'french')
                    return json.dumps({"error": error_msg})

                detected_language = self.detect_language_advanced(question)
                logger.info(f" Langue dÃ©tectÃ©e: {detected_language}")

                is_simple, response_type = self.is_greeting_or_simple_query(question, detected_language)
                if is_simple:
                    response = self.generate_simple_response(response_type, detected_language)
                    self.text_to_speech(response, detected_language)

                    elapsed = time.time() - start_time
                    logger.info(f" RÃ©ponse simple gÃ©nÃ©rÃ©e en {elapsed:.2f} secondes")

                    return json.dumps({
                        "question": question,
                        "response": response,
                        "language": detected_language,
                        "processing_time": elapsed
                    }, ensure_ascii=False)

                passages = self.search_database(question)
            
                response = self.generate_response(question, passages, detected_language)
            
                self.text_to_speech(response, detected_language)
            
                elapsed = time.time() - start_time
                logger.info(f"âœ… Traitement complet en {elapsed:.2f} secondes")
            
                return json.dumps({
                    "question": question,
                    "response": response,
                    "language": detected_language,
                    "processing_time": elapsed
                }, ensure_ascii=False)
        
            elif command["cmd"] == "test_tts":
                test_messages = {
                    'arabic': "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§ ÙÙŠ ØµÙŠØ¯Ù„ÙŠØ© Ø¨Ø§Ø±Ø§Ù„ÙŠØ¨Ù„",
                    'french': "Bonjour et bienvenue Ã  la pharmacie Paralabel",
                    'english': "Hello and welcome to Paralabel pharmacy"
                }
            
                for lang, message in test_messages.items():
                    logger.info(f" Test TTS {lang}: {message}")
                    self.text_to_speech(message, lang)
                    time.sleep(1)
            
                return json.dumps({"status": "TTS test completed"})

            elif command["cmd"] == "reload_database":
                try:
                    if self.db_available:
                        cursor = self.conn.cursor()
                        cursor.execute("DELETE FROM product_embeddings")
                        cursor.execute("DELETE FROM products")
                        self.conn.commit()
                        
                        self.load_knowledge_base()
                        
                        return json.dumps({"status": "Database reloaded successfully"})
                    else:
                        return json.dumps({"error": "Database not available"})
                except Exception as e:
                    logger.error(f"Erreur lors du rechargement: {e}")
                    return json.dumps({"error": f"Reload failed: {str(e)}"})

            elif command["cmd"] == "search_test":
                test_query = command.get("query", "Ã©cran solaire pour peau mixte")
                
                logger.info(f" Test de recherche pour: {test_query}")
                passages = self.search_database(test_query)
                
                return json.dumps({
                    "query": test_query,
                    "results": passages,
                    "count": len(passages)
                }, ensure_ascii=False)
        
            else:
                return json.dumps({"error": "Commande inconnue"})
    
        except Exception as e:
            logger.error(f"âš ï¸ Erreur dans handle_command: {e}")
            return json.dumps({"error": str(e)})

    def test_greeting_detection(self):
        """Test de la dÃ©tection des salutations"""
        test_phrases = [
            "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§",
            "Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙÙƒØŸ",
            "Ù„Ø§Ø¨Ø§Ø³ Ø¹Ù„ÙŠÙƒØŸ",
            "Ø´Ù†Ø­ÙˆØ§Ù„ÙƒØŸ",
            "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±",
            "Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±",
            "Ø´ÙƒØ±Ø§ Ø¨Ø±Ø´Ø§",
            "ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„ØµØ­Ø©",
            
            "Bonjour comment allez-vous ?",
            "Salut Ã§a va ?",
            "Bonsoir",
            "Merci beaucoup",
            
            "Hello how are you?",
            "Hi there!",
            "Good morning",
            "Thank you",
            
            "Propose-moi un Ã©cran solaire pour peau mixte",
            "Ø¨Ù‚Ø¯Ø§Ø´ ÙƒØ±ÙŠÙ… La Roche PosayØŸ",
            "Ø¹Ù†Ø¯ÙƒÙ… Ø´Ø§Ù…Ø¨Ùˆ Ù„Ù„Ø´Ø¹Ø± Ø§Ù„Ø¯Ù‡Ù†ÙŠØŸ",
            "Combien coÃ»te ce produit?",
            "Do you have vitamin C serum?"
        ]
        
        logger.info(" Test de dÃ©tection des salutations:")
        for phrase in test_phrases:
            lang = self.detect_language_advanced(phrase)
            is_greeting_result, greeting_type = self.is_greeting_or_simple_query(phrase, lang)
            logger.info(f"'{phrase}' -> Salutation: {is_greeting_result}, Type: {greeting_type}, Langue: {lang}")
            
            if is_greeting_result:
                response = self.generate_simple_response(greeting_type, lang)
                logger.info(f"  RÃ©ponse: {response}\n")

    def export_database_stats(self):
        """Exporter les statistiques de la base de donnÃ©es"""
        if not self.db_available:
            return {"error": "Database not available"}
        
        try:
            cursor = self.conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM products")
            total_products = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM product_embeddings")
            total_embeddings = cursor.fetchone()[0]
            
            cursor.execute("SELECT category, COUNT(*) FROM products GROUP BY category")
            categories = cursor.fetchall()
            
            cursor.execute("SELECT brand, COUNT(*) FROM products GROUP BY brand ORDER BY COUNT(*) DESC LIMIT 10")
            brands = cursor.fetchall()
            
            return {
                "total_products": total_products,
                "total_embeddings": total_embeddings,
                "categories": dict(categories),
                "top_brands": dict(brands)
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'export des stats: {e}")
            return {"error": str(e)}

    def __del__(self):
        """Fermer la connexion SQLite lors de la destruction de l'objet"""
        try:
            if hasattr(self, 'conn') and self.conn:
                self.conn.close()
                logger.info("Connexion SQLite fermÃ©e")
        except:
            pass

def main():
    try:
        logger.info("ğŸš€ DÃ©marrage de l'assistant vocal Paralabel avec SQLite...")
        
        try:
            assistant = VoiceAssistant(fallback_only=False)
            logger.info("âœ… Assistant vocal initialisÃ© avec SQLite")
        except Exception as e:
            logger.warning(f"âš ï¸ SQLite non disponible, initialisation avec fallback...")
            try:
                assistant = VoiceAssistant(fallback_only=True)
                logger.info("âœ… Assistant vocal initialisÃ© en mode fallback")
            except Exception as e2:
                logger.error(f"âš ï¸ Ã‰chec complet de l'initialisation: {e2}")
                return None
        
        if len(sys.argv) > 1:
            if sys.argv[1] == "--test":
                assistant.test_greeting_detection()
                return assistant
            elif sys.argv[1] == "--stats":
                stats = assistant.export_database_stats()
                print(json.dumps(stats, indent=2, ensure_ascii=False))
                return assistant
        
        return assistant
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Assistant arrÃªtÃ© par l'utilisateur")
        return None
    except Exception as e:
        logger.error(f"âš ï¸ Erreur fatale: {e}")
        return None

if __name__ == "__main__":
    assistant = main()
    
    if assistant:
        logger.info(" Assistant vocal prÃªt - En attente de commandes...")
        logger.info(" Commandes disponibles:")
        logger.info("  - process_audio: Traitement vocal complet")
        logger.info("  - test_tts: Test du systÃ¨me TTS")
        logger.info("  - reload_database: Recharger depuis all_docs.json")
        logger.info("  - search_test: Test de recherche")
        
        try:
            for line in sys.stdin:
                response = assistant.handle_command(line.strip())
                print(response)
                sys.stdout.flush()
        except KeyboardInterrupt:
            logger.info("â¹ï¸ Assistant arrÃªtÃ© par l'utilisateur")
        except Exception as e:
            logger.error(f"âš ï¸ Erreur pendant l'exÃ©cution: {e}")
    else:
        logger.error("âš ï¸ Assistant vocal non disponible")
        sys.exit(1)